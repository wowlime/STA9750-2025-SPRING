[
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "GTA IV - Greener America Awards 2025",
    "section": "",
    "text": "The Green Transit Alliance for Investigation of Variance (GTA IV) is proud to present this years Greener America Awards, where we will be awarding public transit systems all across America for their contribution to environmental conciousness.\n1"
  },
  {
    "objectID": "mp02.html#executive-summary",
    "href": "mp02.html#executive-summary",
    "title": "GTA IV - Greener America Awards 2025",
    "section": "Executive Summary",
    "text": "Executive Summary\nThe US Public Transit System has always been the backbone of transportation in America, serving millions of people everyday all while staying aware of environmental hazards surrounding the use of transportation such as carbon emissions or air pollution. Today, the Green Transit Alliance for Investigation of Variance will be giving awards to honor and congratulate many public transit systems for their commitment to sustainability. We hope that this will inspire more transit systems in America and all around the world to keep the environment sustainable and create awareness on the matter.\n\nThe smaller agencies out there will not go unnoticed as well, here in GTA IV we have calculated ways to award not only the largest and most used public transits, but also small and medium sized ones for their hardwork in preservation to be recognized.\n\nNow, drumroll please as we start the awards‚Ä¶‚Ä¶ü•Åü•Åü•Å"
  },
  {
    "objectID": "mp02.html#greenest-transit-agency-award",
    "href": "mp02.html#greenest-transit-agency-award",
    "title": "GTA IV - Greener America Awards 2025",
    "section": "Greenest Transit Agency Award",
    "text": "Greenest Transit Agency Award\n\nThe winners of the Greenest Transit Agency Award are‚Ä¶.\n\nSmall Agency: City Of Long Beach, with an emission of 0.0765 kilograms of C02 per UPT, with a median score of 2.77 kg of C02 per UPT for small agencies.2\nMedium Agency: Whatcom Transportation Authority, with an emission of 0.0242 kilograms of C02 per UPT, with a median of 1.33 kg of C02 per UPT for medium agencies.\nLarge Agency: Central Florida Regional Transportation Authority, with an emission of 0.000456 kilograms of C02 per UPT, with a median of 0.37 kg of C02 per UPT for large agencies.\n\nThe GTA IV calculated these statistics by computing the total kilograms of C02 emitted per gallon of different gases burned and then divided the total emissions by UPT to find which agencies emit the least amount of C02 by UPT."
  },
  {
    "objectID": "mp02.html#most-emissions-avoided-award",
    "href": "mp02.html#most-emissions-avoided-award",
    "title": "GTA IV - Greener America Awards 2025",
    "section": "Most Emissions Avoided Award",
    "text": "Most Emissions Avoided Award\n\nThe winners of the Most Emissions Avoided Award are‚Ä¶\nSmall Agency: Trans-Bridge Lines, Inc. with 2925138 kilograms of C02 emissions avoided compared to the average standard, with the median emissions avoided being -303903.6 kg of C02 emissions for small agencies.\nMedium Agency: Intercity Transit with 9092042 kilograms of C02 emission avoided compared to the average standard, with the median emissions avoided being -618120.8 kg of C02 emission for medium agencies.\nLarge Agency: MTA New York City Transit with 7299011485 kilograms of C02 emission avoided compared to the average standard, with the median emissions avoided being 7487465.4 kg of C02 emission for large agencies.\n\nThe GTA IV calculated these with the average miles per gallon being around 49 and the average amount of c02 being emitted per gallon being 8.887. Using these metrics, we calculated the hypothetical emissions and subtracted it from the total emissions to compare the total amount of emissions avoided."
  },
  {
    "objectID": "mp02.html#gas-guzzlers-award",
    "href": "mp02.html#gas-guzzlers-award",
    "title": "GTA IV - Greener America Awards 2025",
    "section": "Gas Guzzlers Award",
    "text": "Gas Guzzlers Award\n\nWhile we want to recognize the public transit systems that are keeping the environment sustainable, it is also important to look at the ones that have the most inefficient fuel use and encourage them to do better in the future! The Gas Guzzler award is just that, and hopefully these transit systems are able to improve moving forward. The award goes to‚Ä¶\n\nSmall Agency: Valley Regional Transit, with 4.59 kilograms of C02 emission per mile, with the median emissions avoided being -303903.6 kg of C02 emissions for small agencies.\nMedium Agency: Mid Mon Valley Transit Authority with 4.59 kilograms of C02 emission per mile, with the median emissions avoided being -618120.8 kg of C02 emission for medium agencies.\nLarge Agency: Central Ohio Transit Authroity with 2.61 kilograms of C02 emission per mile, with the median emissions avoided being 7487465.4 kg of C02 emission for large agencies.\n\nThe GTA IV calculated these by dividing the total emissions of all agencies by total amount of miles traveled by the agency. This allowed us to see which agencies in each size bracket emits the most per mile."
  },
  {
    "objectID": "mp02.html#thank-you",
    "href": "mp02.html#thank-you",
    "title": "GTA IV - Greener America Awards 2025",
    "section": "Thank You!",
    "text": "Thank You!\nThese are all the awards we have for this year, but don‚Äôt worry, there will be more next year! Hopefully these awards will motivate more public transit agencies to become environmentally conscious and help with sustainability for years to come."
  },
  {
    "objectID": "mp02.html#appendix",
    "href": "mp02.html#appendix",
    "title": "GTA IV - Greener America Awards 2025",
    "section": "Appendix",
    "text": "Appendix\n\nData Acquisition\nThe data sources used to obtain and examine the data are the following:\n1. The US Electricity Profile 2023 from the U.S. Energy Information Administration\n2. The 2023 Annual Database Energy Consumption from the Federal Transit Administration\n3.The 2023 Service by Agency Report from the U.S. Office of Personnel Management\n4.The Carbon Dioxide Emissions Coefficients from the U.S. Energy Information Administration\n\n\n\nInitial Analysis and Organization\n\nEIA State Electricity Profiles\n\n\nCode\nensure_package(dplyr)\nensure_package(stringr)\nensure_package(tidyr)\nensure_package(httr2)\nensure_package(rvest)\nensure_package(datasets)\nensure_package(purrr)\nensure_package(DT)\nensure_package(readxl)\n\nget_eia_sep &lt;- function(state, abbr){\n  state_formatted &lt;- str_to_lower(state) |&gt; str_replace_all(\"\\\\s\", \"\")\n  \n  dir_name &lt;- file.path(\"data\", \"mp02\")\n  file_name &lt;- file.path(dir_name, state_formatted)\n  \n  dir.create(dir_name, showWarnings=FALSE, recursive=TRUE)\n  \n  if(!file.exists(file_name)){\n    BASE_URL &lt;- \"https://www.eia.gov\"\n    REQUEST &lt;- request(BASE_URL) |&gt; \n      req_url_path(\"electricity\", \"state\", state_formatted)\n    \n    RESPONSE &lt;- req_perform(REQUEST)\n    \n    resp_check_status(RESPONSE)\n    \n    writeLines(resp_body_string(RESPONSE), file_name)\n  }\n  \n  TABLE &lt;- read_html(file_name) |&gt; \n    html_element(\"table\") |&gt; \n    html_table() |&gt;\n    mutate(Item = str_to_lower(Item))\n  \n  if(\"U.S. rank\" %in% colnames(TABLE)){\n    TABLE &lt;- TABLE |&gt; rename(Rank = `U.S. rank`)\n  }\n  \n  CO2_MWh &lt;- TABLE |&gt; \n    filter(Item == \"carbon dioxide (lbs/mwh)\") |&gt;\n    pull(Value) |&gt; \n    str_replace_all(\",\", \"\") |&gt;\n    as.numeric()\n  \n  PRIMARY &lt;- TABLE |&gt; \n    filter(Item == \"primary energy source\") |&gt; \n    pull(Rank)\n  \n  RATE &lt;- TABLE |&gt;\n    filter(Item == \"average retail price (cents/kwh)\") |&gt;\n    pull(Value) |&gt;\n    as.numeric()\n  \n  GENERATION_MWh &lt;- TABLE |&gt;\n    filter(Item == \"net generation (megawatthours)\") |&gt;\n    pull(Value) |&gt;\n    str_replace_all(\",\", \"\") |&gt;\n    as.numeric()\n  \n  data.frame(CO2_MWh               = CO2_MWh, \n             primary_source        = PRIMARY,\n             electricity_price_MWh = RATE * 10, # / 100 cents to dollars &\n             # * 1000 kWh to MWH \n             generation_MWh        = GENERATION_MWh, \n             state                 = state, \n             abbreviation          = abbr\n  )\n}\nEIA_SEP_REPORT &lt;- map2(state.name, state.abb, get_eia_sep) |&gt; list_rbind()\nensure_package(scales)\nensure_package(DT)\n\nEIA_SEP_REPORT |&gt; \n    select(-abbreviation) |&gt;\n    arrange(desc(CO2_MWh)) |&gt;\n    mutate(CO2_MWh = number(CO2_MWh, big.mark=\",\"), \n           electricity_price_MWh = dollar(electricity_price_MWh), \n           generation_MWh = number(generation_MWh, big.mark=\",\")) |&gt;\n    rename(`Pounds of CO2 Emitted per MWh of Electricity Produced`=CO2_MWh, \n           `Primary Source of Electricity Generation`=primary_source, \n           `Average Retail Price for 1000 kWh`=electricity_price_MWh, \n           `Total Generation Capacity (MWh)`= generation_MWh, \n           State=state) |&gt;\n    datatable()\n\n\n\n\n\n\nQuestion 1: Which state has the most expensive retail electricity?\nFrom the table, we can see Hawaii has the most expensive retail electricity costing an average of $386 per 1000 kWh.\n\nQuestion 2: Which state has the ‚Äòdirtiest‚Äô electricity mix?\nFrom the table, we can see the state with the dirtiest electricity mix is West Virginia, with 1925 pounds of CO2 emitted per MWh of electricity produced\n\nQuestion 3: On average, how many pounds of CO2 are emitted per MWh of electricity produced in the US?\n\n\n\nCode\naverage_CO2_per_MWh &lt;- EIA_SEP_REPORT |&gt; \n  summarise(weighted_avg_CO2 = sum(CO2_MWh * generation_MWh) / sum(generation_MWh))\naverage_CO2_per_MWh |&gt; \n  kable(caption = \"Average CO2 Emissions per MWh\")\n\n\n\nAverage CO2 Emissions per MWh\n\n\nweighted_avg_CO2\n\n\n\n\n805.3703\n\n\n\n\n\nQuestion 4: What is the rarest primary energy source in the US? What is the associated cost of electricity and where is it used?\n\n\n\nCode\nrarest_energy_source &lt;- EIA_SEP_REPORT |&gt; \n  group_by(primary_source) |&gt; \n  summarise(total_generation = sum(generation_MWh, na.rm = TRUE)) |&gt; \n  filter(total_generation == min(total_generation, na.rm = TRUE))\nrarest_energy_source |&gt; \n  kable(caption = \"Rarest Energy Source by Total Generation\")\n\n\n\nRarest Energy Source by Total Generation\n\n\nprimary_source\ntotal_generation\n\n\n\n\nPetroleum\n9194164\n\n\n\n\n\nQuestion 5:Texas has a reputation as being the home of ‚Äúdirty fossil fuels‚Äù while NY has a reputation as a leader in clean energy. How many times cleaner is NY‚Äôs energy mix than that of Texas?\n\n\n\nCode\nny_cleanliness &lt;- EIA_SEP_REPORT |&gt; \n  filter(state == \"New York\") |&gt; \n  pull(CO2_MWh)\n\ntx_cleanliness &lt;- EIA_SEP_REPORT |&gt; \n  filter(state == \"Texas\") |&gt; \n  pull(CO2_MWh)\nclean_ratio &lt;- tx_cleanliness / ny_cleanliness\nclean_ratio_df &lt;- data.frame(State_Comparison = c(\"Texas vs New York\"), Clean_Ratio = clean_ratio)\nclean_ratio_df |&gt; \n  kable(caption = \"CO2 per MWh Ratio: Texas vs New York\")\n\n\n\nCO2 per MWh Ratio: Texas vs New York\n\n\nState_Comparison\nClean_Ratio\n\n\n\n\nTexas vs New York\n1.637931\n\n\n\n\n\n\n\n2023 Annual Database Energy Consumption\n\n\nCode\nensure_package(readxl)\n# Create 'data/mp02' directory if not already present\nDATA_DIR &lt;- file.path(\"data\", \"mp02\")\ndir.create(DATA_DIR, showWarnings=FALSE, recursive=TRUE)\n\nNTD_ENERGY_FILE &lt;- file.path(DATA_DIR, \"2023_ntd_energy.xlsx\")\n\nif(!file.exists(NTD_ENERGY_FILE)){\n    DS &lt;- download.file(\"https://www.transit.dot.gov/sites/fta.dot.gov/files/2024-10/2023%20Energy%20Consumption.xlsx\", \n                  destfile=NTD_ENERGY_FILE, \n                  method=\"curl\")\n    \n    if(DS | (file.info(NTD_ENERGY_FILE)$size == 0)){\n        cat(\"I was unable to download the NTD Energy File. Please try again.\\n\")\n        stop(\"Download failed\")\n    }\n}\n\nNTD_ENERGY_RAW &lt;- read_xlsx(NTD_ENERGY_FILE)\n\n\nWarning: Expecting numeric in R1197 / R1197C18: got '-'\n\n\nCleaning data and updating all the modes\n\n\nCode\nensure_package(tidyr)\nto_numeric_fill_0 &lt;- function(x){\n    x &lt;- if_else(x == \"-\", NA, x)\n    replace_na(as.numeric(x), 0)\n}\n\nNTD_ENERGY &lt;- NTD_ENERGY_RAW |&gt; \n    select(-c(`Reporter Type`, \n              `Reporting Module`, \n              `Other Fuel`, \n              `Other Fuel Description`)) |&gt;\n    mutate(across(-c(`Agency Name`, \n                     `Mode`,\n                     `TOS`), \n                  to_numeric_fill_0)) |&gt;\n    group_by(`NTD ID`, `Mode`, `Agency Name`) |&gt;\n    summarize(across(where(is.numeric), sum), \n              .groups = \"keep\") |&gt;\n    mutate(ENERGY = sum(c_across(c(where(is.numeric))))) |&gt;\n    filter(ENERGY &gt; 0) |&gt;\n    select(-ENERGY) |&gt;\n    ungroup()\nNTD_ENERGY &lt;- NTD_ENERGY |&gt;\n  mutate(Mode = case_when(\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"SR\" ~ \"Streetcar\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"MG\" ~ \"Monorail/Automated Guideway\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"AR\" ~ \"Alaska Railroad\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"\n  ))\n\n\n\n\n2023 Annual Database service by Agency\nImporting and cleaning data\n\n\nCode\nNTD_SERVICE_FILE &lt;- file.path(DATA_DIR, \"2023_service.csv\")\nif(!file.exists(NTD_SERVICE_FILE)){\n  DS &lt;- download.file(\"https://data.transportation.gov/resource/6y83-7vuw.csv\", \n                      destfile=NTD_SERVICE_FILE, \n                      method=\"curl\")\n  \n  if(DS | (file.info(NTD_SERVICE_FILE)$size == 0)){\n    cat(\"I was unable to download the NTD Service File. Please try again.\\n\")\n    stop(\"Download failed\")\n  }\n}\n\nNTD_SERVICE_RAW &lt;- read_csv(NTD_SERVICE_FILE)\n\n\nRows: 1000 Columns: 35\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr  (8): _5_digit_ntd_id, agency, max_reporter_type, max_organization_type,...\ndbl (27): report_year, max_agency_voms, max_primary_uza_area_sq_miles, max_p...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nNTD_SERVICE &lt;- NTD_SERVICE_RAW |&gt;\n  mutate(`NTD ID` = as.numeric(`_5_digit_ntd_id`)) |&gt; \n  rename(Agency = agency, \n         City   = max_city, \n         State  = max_state,\n         UPT    = sum_unlinked_passenger_trips_upt, \n         MILES  = sum_passenger_miles) |&gt;\n  select(matches(\"^[A-Z]\", ignore.case=FALSE)) |&gt;\n  filter(MILES &gt; 0)\n\n\nQuestion 1:Which transit service has the most UPT annually?\n\n\n\nCode\nmost_upt_service &lt;- NTD_SERVICE |&gt;\n  arrange(desc(UPT)) |&gt;\n  slice(1) |&gt;\n  select(Agency, City, State, UPT)\nmost_upt_service |&gt; \n  kable(caption = \"Agency with the Most UPT\")\n\n\n\nAgency with the Most UPT\n\n\nAgency\nCity\nState\nUPT\n\n\n\n\nMTA New York City Transit\nBrooklyn\nNY\n2632003044\n\n\n\n\n\nQuestion 2:What is the average trip length of a trip on MTA NYC?\n\n\nCode\nmta_nyc_avg_trip_length &lt;- NTD_SERVICE |&gt;\n  filter(grepl(\"MTA\", Agency)) |&gt;  \n  mutate(avg_trip_length = MILES / UPT) |&gt;\n  summarize(avg_trip_length = mean(avg_trip_length, na.rm = TRUE))\nmta_nyc_avg_trip_length |&gt; \n  kable(caption = \"Average Trip Length for MTA NYC\")\n\n\n\nAverage Trip Length for MTA NYC\n\n\navg_trip_length\n\n\n\n\n10.71179\n\n\n\n\n\nQuestion 3:Which transit service in NYC has the longest average trip length?\n\n\nCode\nnyc_longest_trip &lt;- NTD_SERVICE |&gt;\n  filter(City %in% c(\"New York City\", \"Brooklyn\")) |&gt;\n  mutate(avg_trip_length = MILES / UPT) |&gt;\n  arrange(desc(avg_trip_length)) |&gt;\n  slice(1) |&gt;\n  select(Agency, City, avg_trip_length)\nnyc_longest_trip |&gt; \n  kable(caption = \"City with the Longest Average Trip Length in NYC\")\n\n\n\nCity with the Longest Average Trip Length in NYC\n\n\nAgency\nCity\navg_trip_length\n\n\n\n\nPrivate Transportation Corporation\nBrooklyn\n5.233385\n\n\n\n\n\nQuestion 4:Which state has the fewest total miles travelled by public transit?\n\n\nCode\nstate_fewest_miles &lt;- NTD_SERVICE |&gt;\n  group_by(State) |&gt;\n  summarize(total_miles = sum(MILES, na.rm = TRUE)) |&gt;\n  arrange(total_miles) |&gt;\n  slice(1)\nstate_fewest_miles |&gt;\n  kable(caption = \"State with the Fewest Total Miles\")\n\n\n\nState with the Fewest Total Miles\n\n\nState\ntotal_miles\n\n\n\n\nNH\n3749892\n\n\n\n\n\nQuestion 5:Are all states represented in this data?\n\n\nCode\nall_states &lt;- state.abb \nmissing_states &lt;- setdiff(all_states, unique(NTD_SERVICE$State))\n\nmissing_states |&gt;\n  kable(caption = \"States Missing from the NTD_Service Dataset\")\n\n\n\nStates Missing from the NTD_Service Dataset\n\n\nx\n\n\n\n\nAZ\n\n\nAR\n\n\nCA\n\n\nCO\n\n\nHI\n\n\nIA\n\n\nKS\n\n\nLA\n\n\nMO\n\n\nMT\n\n\nNE\n\n\nNV\n\n\nNM\n\n\nND\n\n\nOK\n\n\nSD\n\n\nTX\n\n\nUT\n\n\nWY\n\n\n\n\n\n\n\nJoining Datasets\n\n\nCode\ncolnames(NTD_SERVICE)[which(names(NTD_SERVICE) == \"Agency\")] &lt;- \"Agency Name\"\nEIA_SEP_REPORT &lt;- EIA_SEP_REPORT |&gt; select(-state)\nNTD_SERVICE &lt;- NTD_SERVICE |&gt; mutate(State = as.character(State))\nEIA_SEP_REPORT &lt;- EIA_SEP_REPORT |&gt; mutate(abbreviation = as.character(abbreviation))\ncombined_data &lt;- NTD_SERVICE |&gt; \n  inner_join(NTD_ENERGY, by = c(\"NTD ID\", \"Agency Name\"))\nfinal_data &lt;- combined_data |&gt; \n  left_join(EIA_SEP_REPORT, by = c(\"State\" = \"abbreviation\"))\nfinal_data |&gt; \n  head() |&gt;\n  kable(caption = \"Preview of Final Combined Data\")\n\n\n\nPreview of Final Combined Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgency Name\nCity\nState\nUPT\nMILES\nNTD ID\nMode\nBio-Diesel\nBunker Fuel\nC Natural Gas\nDiesel Fuel\nElectric Battery\nElectric Propulsion\nEthanol\nMethonal\nGasoline\nHydrogen\nKerosene\nLiquified Nat Gas\nLiquified Petroleum Gas\nCO2_MWh\nprimary_source\nelectricity_price_MWh\ngeneration_MWh\n\n\n\n\nSpokane Transit Authority\nSpokane\nWA\n9403739\n46318134\n2\nDemand Response\n0\n0\n0\n131642\n0\n0\n0\n0\n152360\n0\n0\n0\n0\n292\nHydroelectric\n95.8\n102960605\n\n\nSpokane Transit Authority\nSpokane\nWA\n9403739\n46318134\n2\nBus\n0\n0\n0\n1335531\n1202138\n0\n0\n0\n0\n0\n0\n0\n0\n292\nHydroelectric\n95.8\n102960605\n\n\nSpokane Transit Authority\nSpokane\nWA\n9403739\n46318134\n2\nVanpool\n0\n0\n0\n0\n0\n0\n0\n0\n56463\n0\n0\n0\n0\n292\nHydroelectric\n95.8\n102960605\n\n\nLane Transit District\nEugene\nOR\n6311613\n22779952\n7\nDemand Response\n0\n0\n0\n0\n0\n0\n0\n0\n94756\n0\n0\n0\n0\n344\nHydroelectric\n103.2\n61691869\n\n\nLane Transit District\nEugene\nOR\n6311613\n22779952\n7\nBus\n0\n0\n0\n450303\n920696\n0\n0\n0\n5806\n0\n0\n0\n0\n344\nHydroelectric\n103.2\n61691869\n\n\nLane Transit District\nEugene\nOR\n6311613\n22779952\n7\nBus Rapid Transit\n212371\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n344\nHydroelectric\n103.2\n61691869\n\n\n\n\n\nAfter joining the three tables, we used mutute to compute the total emissions for the row using data from the EIA website.\n\n\nCode\nfinal_data &lt;- final_data |&gt; \n  mutate(\n    total_emissions = (`Diesel Fuel` * 10.21) +\n      (`Gasoline` * 8.89) +\n      (`C Natural Gas` * 53.06) +\n      (`Liquified Petroleum Gas` * 5.79) +\n      (`Bio-Diesel` * 9.45) +\n      (`Ethanol` * 1.94) +\n      (`Hydrogen` * 0) +\n      (`Kerosene` * 9.75) +\n      (`Liquified Nat Gas` * 62.44) +\n      (`Bunker Fuel` * 10.96) +\n      (`Electric Battery` * CO2_MWh / 1000) +  # Convert to metric tons\n      (`Electric Propulsion` * CO2_MWh / 1000)\n  )\n\n\n\n\nNormalizing Emissions to Transit Usage\nWe categorized the agencies by size by the UPT of each transit system, with systems that have over 5000000 considered large, 500000 to 5000000 considered medium, and anything less is a small agency. We also calculated the emissions per UPT and emissions per mile by dividing total emissions by UPT and dividing total_emissions by total miles.\n\n\nCode\nfinal_data &lt;- final_data |&gt; \n  group_by(`Agency Name`) |&gt; \n  mutate(\n    emissions_per_UPT = total_emissions / UPT,\n    emissions_per_mile = total_emissions / MILES\n  ) |&gt; \n  ungroup()\nfinal_data &lt;- final_data |&gt; \n  group_by(`Agency Name`) |&gt; \n  mutate(\n    agency_size = case_when(\n      UPT &gt;= 5000000 ~ \"Large\",\n      UPT &gt;= 500000 ~ \"Medium\",\n      TRUE ~ \"Small\"\n    )\n  ) |&gt; \n  ungroup()\n\n\nCode for Emissions per UPT:\n\n\nCode\nmost_efficient &lt;- final_data |&gt; \n  group_by(agency_size, `Agency Name`) |&gt; \n  summarize(\n    avg_emissions_per_UPT = mean(emissions_per_UPT, na.rm = TRUE),\n    avg_emissions_per_mile = mean(emissions_per_mile, na.rm = TRUE)\n  ) |&gt; \n  arrange(agency_size, avg_emissions_per_UPT, avg_emissions_per_mile)\n\n\n`summarise()` has grouped output by 'agency_size'. You can override using the\n`.groups` argument.\n\n\nCode\nbest_efficiency &lt;- most_efficient |&gt; \n  group_by(agency_size) |&gt; \n  slice_min(order_by = avg_emissions_per_UPT, n = 1)\n\n\nGreenest Agencies Calculation Code\nWe calculated this by filtering by emissions_per_UPT to see the lowest for every agency size to get the 3 greenest agencies.\n\n\nCode\nmedian_emissions &lt;- final_data |&gt;\n  group_by(agency_size) |&gt;\n  summarise(median_emissions_per_UPT = median(emissions_per_UPT, na.rm = TRUE))\ngreenest_agencies &lt;- final_data |&gt;\n  group_by(agency_size) |&gt;\n  filter(emissions_per_UPT == min(emissions_per_UPT, na.rm = TRUE)) |&gt;\n  ungroup()\ngreenest_agencies |&gt;\n  select(`Agency Name`, agency_size, emissions_per_UPT) |&gt;\n  left_join(median_emissions, by = \"agency_size\") |&gt;\n  kable(caption = \"Greenest Agencies and Median Emissions per UPT by Agency Size\")\n\n\n\nGreenest Agencies and Median Emissions per UPT by Agency Size\n\n\n\n\n\n\n\n\nAgency Name\nagency_size\nemissions_per_UPT\nmedian_emissions_per_UPT\n\n\n\n\nWhatcom Transportation Authority\nMedium\n0.0241804\n1.3337899\n\n\nCity of Long Beach\nSmall\n0.0764815\n2.7111502\n\n\nCentral Florida Regional Transportation Authority\nLarge\n0.0004559\n0.3708156\n\n\n\n\n\nCode\nmedian_emissions_fixed &lt;- median_emissions |&gt; distinct()\n\nggplot(greenest_agencies |&gt; left_join(median_emissions, by = \"agency_size\"), \n       aes(x = agency_size, y = emissions_per_UPT, fill = `Agency Name`)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_hline(data = median_emissions_fixed, aes(yintercept = median_emissions_per_UPT, color = agency_size), \n             linetype = \"dashed\", size = 1.2) +\n  scale_color_manual(values = c(\"Large\" = \"blue\", \"Medium\" = \"green\", \"Small\" = \"red\")) + \n  labs(title = \"Greenest Agencies vs. Median Emissions per UPT\",\n       x = \"Agency Size\", \n       y = \"Emissions per UPT\",\n       fill = \"Best Agency\",\n       color = \"Median Line\") + \n  theme_minimal()\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nFrom the plot, we are able to see the median emission per UPT from the line, while the bars represent the agencies with the lowest emission, showing how big of an impact they are making with lower emissions. Most Emissions Avoided Award Calculation Code\nWe calculated this by finding the average mile per gallon of a vehicle and the C02 emission per gallon and found the hypothetical emission by diving miles by average mile per gallon and then multiplying it by galloon. We then subtracted the hypothetical emissions by total emissions to see which agencies saved the most.\n\n\nCode\nfuel_economy_mpg &lt;- 49\nco2_per_gallon &lt;- 8.887\nfinal_data &lt;- final_data |&gt;\n  mutate(hypothetical_emissions = (MILES / fuel_economy_mpg) * co2_per_gallon,\n         emissions_avoided = hypothetical_emissions - total_emissions)\nmost_emissions_avoided &lt;- final_data |&gt;\n  group_by(agency_size, `Agency Name`) |&gt;\n  summarise(total_emissions_avoided = sum(emissions_avoided, na.rm = TRUE)) |&gt;\n  arrange(desc(total_emissions_avoided)) |&gt;\n  slice(1)\n\n\n`summarise()` has grouped output by 'agency_size'. You can override using the\n`.groups` argument.\n\n\nCode\nmedian_emissions_avoided &lt;- final_data |&gt;\n  group_by(agency_size) |&gt;\n  summarise(median_emissions_avoided = median(emissions_avoided, na.rm = TRUE))\nfinal_results &lt;- most_emissions_avoided |&gt;\n  left_join(median_emissions_avoided, by = \"agency_size\")\nkable(final_results, caption = \"Agency with the Most Emissions Avoided and Median Emissions Avoided by Agency Size\")\n\n\n\nAgency with the Most Emissions Avoided and Median Emissions Avoided by Agency Size\n\n\n\n\n\n\n\n\nagency_size\nAgency Name\ntotal_emissions_avoided\nmedian_emissions_avoided\n\n\n\n\nLarge\nMTA New York City Transit\n7299011485\n7487465.4\n\n\nMedium\nIntercity Transit\n9092042\n-618120.8\n\n\nSmall\nTrans-Bridge Lines, Inc.\n2925138\n-303803.6\n\n\n\n\n\nGas Guzzlers Award Calculation Code\nWe calculated Gas Guzzlers by filtering to see which agencies emit the most C02 by mile.\n\n\nCode\ngas_guzzler_award &lt;- final_data |&gt;\n  group_by(agency_size) |&gt;\n  filter(emissions_per_mile == max(emissions_per_mile, na.rm = TRUE)) |&gt;\n  select(`Agency Name`, City, State, agency_size, emissions_per_mile, total_emissions)\nkable(gas_guzzler_award, caption = \"Gas Guzzler Award - Agency with Highest Emissions Per Mile\")\n\n\n\nGas Guzzler Award - Agency with Highest Emissions Per Mile\n\n\n\n\n\n\n\n\n\n\nAgency Name\nCity\nState\nagency_size\nemissions_per_mile\ntotal_emissions\n\n\n\n\nValley Regional Transit\nMeridian\nID\nMedium\n4.591114\n20562056\n\n\nMid Mon Valley Transit Authority\nCharleroi\nPA\nSmall\n4.586857\n10641127\n\n\nCentral Ohio Transit Authority\nColumbus\nOH\nLarge\n2.606710\n133676175\n\n\n\n\n\nCode\nggplot(final_data, aes(x = agency_size, y = emissions_per_UPT, fill = agency_size)) + \n  geom_boxplot() + \n  scale_y_log10() + \n  labs(title = \"Distribution of Emissions per UPT by Agency Size\", \n       x = \"Agency Size\", \n       y = \"Emissions per UPT (log scale)\") + \n  theme_minimal()\n\n\nWarning: Removed 4 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nWe had to scale the plot using log because the values for large agencies were too big, then we are able to visualize the distributions per UPT by agency size and the dots represent outliers in those plots. Based off the graph, we can see the highest points, lowest points, and the median."
  },
  {
    "objectID": "mp02.html#footnotes",
    "href": "mp02.html#footnotes",
    "title": "GTA IV - Greener America Awards 2025",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAll images were created using Canva AI Image Generator‚Ü©Ô∏é\nUnlinked Passenger Trips, the distinct number of trips taken on public transit.‚Ü©Ô∏é"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi, I‚Äôm Jackey",
    "section": "",
    "text": "Nice to meet you! My name is Jackey and I am currently a student at Baruch pursing a masters in Business Analytics as of Spring 2025 where I am developing skills in statistical analysis, data-driven decision-making, and business intellegence. I am passionate about applying analytical tools to optimize business performance and drive meaningful insights.\nMy hobbies include playing video games, rock climbing, reading books, and going to the gym.\nBelow I have attached my resume\nHere\n\nLast Updated: Tuesday 03 25, 2025 at 22:54PM"
  },
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "New York City Payroll Policy Proposal Analysis",
    "section": "",
    "text": "This white paper is for the analysis of New York City‚Äôs payroll data and policies that the Commission to Analyze Taxpayer Spending (CATS) have created with recommendations on how to optimize tax payer‚Äôs money more efficiently. We will be looking through two policies from CATS, analyzing if they are policies that should be adopted or not, and one additional suggested policy for CATS to adopt that will reduce expenses and city payroll. The policies we will be looking at are as follows:\n\nCapping Salaries at Mayoral Level: This proposal from CATS is a traditional policy that is implementented in many other governments already but not yet in the city of New York. Implimenting this policy could potentially save the city money but can lead to more problems down the line.\nIncreasing Staffing to Reduce Overtime Expenses: This policy suggests hiring additional employees to reduce excessive overtime pay. There are many employees that work many overtime hours which leads to higher payroll costs and by hiring more employees,and overall it could reduce overtime expenses.\nAdjusting Pay Based on Geographic Location: Our suggestion to CATS to effectively save city payroll is to adjust salaries based on the work location borough to reflect on living costs where some may have a higher cost of living while others have lower."
  },
  {
    "objectID": "mp01.html#purpose",
    "href": "mp01.html#purpose",
    "title": "New York City Payroll Policy Proposal Analysis",
    "section": "",
    "text": "This white paper is for the analysis of New York City‚Äôs payroll data and policies that the Commission to Analyze Taxpayer Spending (CATS) have created with recommendations on how to optimize tax payer‚Äôs money more efficiently. We will be looking through two policies from CATS, analyzing if they are policies that should be adopted or not, and one additional suggested policy for CATS to adopt that will reduce expenses and city payroll. The policies we will be looking at are as follows:\n\nCapping Salaries at Mayoral Level: This proposal from CATS is a traditional policy that is implementented in many other governments already but not yet in the city of New York. Implimenting this policy could potentially save the city money but can lead to more problems down the line.\nIncreasing Staffing to Reduce Overtime Expenses: This policy suggests hiring additional employees to reduce excessive overtime pay. There are many employees that work many overtime hours which leads to higher payroll costs and by hiring more employees,and overall it could reduce overtime expenses.\nAdjusting Pay Based on Geographic Location: Our suggestion to CATS to effectively save city payroll is to adjust salaries based on the work location borough to reflect on living costs where some may have a higher cost of living while others have lower."
  },
  {
    "objectID": "mp01.html#objective",
    "href": "mp01.html#objective",
    "title": "New York City Payroll Policy Proposal Analysis",
    "section": "Objective",
    "text": "Objective\nThe objective for our analysis is to see how these possible policies will affect overall spending and we will do that by computing each policies impact on city payroll and determing if any staffing adjustments are required to implement the policy."
  },
  {
    "objectID": "mp01.html#initial-data",
    "href": "mp01.html#initial-data",
    "title": "New York City Payroll Policy Proposal Analysis",
    "section": "Initial Data",
    "text": "Initial Data\nFor the analysis, we are using the NYC Payroll Data. We first want to look at all the data provided and standardize the data to usE and see what is applicable to the questions we want to answer, and from the dataset we are able to view an example of the different columns provided. Some key variables that we want to focus on include but are not limited to fiscal_year, agency_name, title description, base_salary, total_ot_paid, regular_hours, and ot_hours.\n\n\nCode\n# calcuating how much payroll increases per year\npayroll_growth &lt;- df |&gt; \n  group_by(fiscal_year) |&gt; \n  summarize(total_payroll = sum(base_salary + total_ot_paid, na.rm = TRUE)) |&gt; \n  arrange(fiscal_year) |&gt; \n  mutate(percentage_increase = (total_payroll - lag(total_payroll)) / lag(total_payroll) * 100) |&gt; \n  drop_na(percentage_increase)  \n#plotting of the data\nggplot(payroll_growth, aes(x = fiscal_year, y = percentage_increase)) +\n  geom_line(color = \"steelblue\", linewidth = 1) +  \n  geom_point(color = \"steelblue\", size = 2) +\n  labs(title = \"Year-over-Year Percentage Increase in Aggregate Payroll\",\n       x = \"Fiscal Year\",\n       y = \"Percentage Increase (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nHere we can see the changes in aggregated payroll per year, with 2015 having the biggest increase by 13% and it was common for the payroll spending to increase slowly every year. If this trend were to continue there would be too much payroll spending and the cost needs to be controlled.\n\nStandardization\n\n\nCode\n#standardizing data\ndf &lt;- df |&gt;\n  mutate(\n    `agency_name` = str_to_title(`agency_name`),\n    `last_name` = str_to_title(`last_name`),\n    `first_name` = str_to_title(`first_name`),\n    `work_location_borough` = str_to_title(`work_location_borough`),\n    `title_description` = str_to_title(`title_description`),\n    `leave_status` = str_to_title(`leave_status_as_of_june_30`)\n  )\n\n\nWe standardized the data by converting all the strings using the ‚Äústr_to_title‚Äù function so only the first letter of the word is capitalized to have a more concise data table.\n\n\nCode\n#small dataset showing a sample of payroll data\ndf |&gt;\n  head(5)|&gt;\n  kable(caption = \"Sample of Payroll Data\")\n\n\n\nSample of Payroll Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiscal_year\npayroll_number\nagency_name\nlast_name\nfirst_name\nmid_init\nagency_start_date\nwork_location_borough\ntitle_description\nleave_status_as_of_june_30\nbase_salary\npay_basis\nregular_hours\nregular_gross_paid\not_hours\ntotal_ot_paid\ntotal_other_pay\nleave_status\n\n\n\n\n2024\n67\nAdmin For Children‚Äôs Svcs\nFaye Fall\nSokhna\nM\n2023-11-20\nBronx\nChild Protective Specialist\nACTIVE\n62043\nper Annum\n1050.00\n31267.96\n12.00\n425.00\n78.04\nActive\n\n\n2024\n67\nAdmin For Children‚Äôs Svcs\nKilgore\nOrlantha\nB\n2023-08-28\nBrooklyn\nChild Protective Specialist\nACTIVE\n62043\nper Annum\n1470.00\n44660.96\n99.75\n3859.84\n78.14\nActive\n\n\n2024\n67\nAdmin For Children‚Äôs Svcs\nWisdom\nCherise\nM\n2022-10-24\nManhattan\nCommunity Associate\nON LEAVE\n43144\nper Annum\n1251.50\n28649.20\n30.00\n802.42\n78.26\nOn Leave\n\n\n2024\n67\nAdmin For Children‚Äôs Svcs\nMiller\nMoya-Gaye\nS\n2023-02-27\nManhattan\nChild Protective Specialist\nON LEAVE\n62043\nper Annum\n1400.75\n44515.43\n44.75\n1476.98\n78.37\nOn Leave\n\n\n2024\n67\nAdmin For Children‚Äôs Svcs\nBradley\nYashika\nM\n2023-02-27\nBronx\nChild Protective Specialist\nCEASED\n60236\nper Annum\n700.00\n22133.64\n53.00\n1933.33\n78.47\nCeased\n\n\n\n\n\nNext, we will start looking at the policies and some key findings and information that CATS wanted us to provide for analysis."
  },
  {
    "objectID": "mp01.html#policy-1-capping-salaries-at-mayoral-level",
    "href": "mp01.html#policy-1-capping-salaries-at-mayoral-level",
    "title": "New York City Payroll Policy Proposal Analysis",
    "section": "Policy 1: Capping Salaries at Mayoral Level ",
    "text": "Policy 1: Capping Salaries at Mayoral Level \n\n\nCode\n#calculating Mayor Eric Adam's salary and position each year\ndf_mayor &lt;- df |&gt; \n  filter(first_name == 'Eric', last_name == 'Adams', mid_init == 'L') |&gt;\n  select(fiscal_year, title_description, agency_name, base_salary) |&gt;\n  rename('Fiscal Year' = fiscal_year,\n         'Position' = title_description,\n         'Agency' = agency_name,\n         'Total Salary' = base_salary) |&gt;\n  group_by(`Fiscal Year`) |&gt;  \n  summarize(\n    `Total Salary` = sum(`Total Salary`),\n    `Position` = paste(unique(`Position`), collapse = \" / \"),  \n    `Agency` = paste(unique(`Agency`), collapse = \" / \")  \n  ) |&gt;  \n  arrange(`Fiscal Year`) |&gt;\n  kable(caption = \"Mayor's Career Path and Salary\", \n        format = \"pipe\")\n\ndf_mayor\n\n\n\nMayor‚Äôs Career Path and Salary\n\n\n\n\n\n\n\n\nFiscal Year\nTotal Salary\nPosition\nAgency\n\n\n\n\n2014\n160000\nBorough President\nBorough President-Brooklyn\n\n\n2015\n160000\nBorough President\nBorough President-Brooklyn\n\n\n2016\n179200\nBorough President\nBorough President-Brooklyn\n\n\n2017\n179200\nBorough President\nBorough President-Brooklyn\n\n\n2018\n179200\nBorough President\nBorough President-Brooklyn\n\n\n2019\n179200\nBorough President\nBorough President-Brooklyn\n\n\n2020\n179200\nBorough President\nBorough President-Brooklyn\n\n\n2021\n179200\nBorough President\nBorough President-Brooklyn\n\n\n2022\n437950\nBorough President / Mayor\nBorough President-Brooklyn / Office Of The Mayor\n\n\n2023\n258750\nMayor\nOffice Of The Mayor\n\n\n2024\n258750\nMayor\nOffice Of The Mayor\n\n\n\n\n\nAs you can see from the data, there was one anomaly where Mayor Eric Adams transitioned from Borough President to Mayor of New York, instead of seperating each of the salaries we decided to put them together although he may have not earned that amount total. To make it simpler to calculate everything.\n\n\nCode\n#Calcuating mayor salary\nmayor_salaries &lt;- df |&gt; \n  filter(title_description == \"Mayor\") |&gt; \n  group_by(fiscal_year) |&gt; \n  summarize(base_salary_mayor = max(base_salary, na.rm = TRUE))\n#combining dataset to see which jobs have a base salary that is higher than the base of the mayor\ndf_updated &lt;- df |&gt; \n  left_join(mayor_salaries, by = \"fiscal_year\") |&gt; \n  mutate(above_mayor_salary = base_salary &gt; base_salary_mayor)\n#filtering to see the top 10 employees that make more than the mayor\nemployees_above_mayor &lt;- df_updated |&gt; \n  filter(above_mayor_salary) |&gt; \n  select(fiscal_year, agency_name, title_description, base_salary, base_salary_mayor)\nkable(head(employees_above_mayor, 10), caption = \"Top 10 Employees Earning More Than the Mayor\")\n\n\n\nTop 10 Employees Earning More Than the Mayor\n\n\n\n\n\n\n\n\n\nfiscal_year\nagency_name\ntitle_description\nbase_salary\nbase_salary_mayor\n\n\n\n\n2024\nAdmin For Children‚Äôs Svcs\nDeputy Commissioner\n258866\n258750\n\n\n2024\nAdmin For Children‚Äôs Svcs\nAdministrative Staff Analyst\n264748\n258750\n\n\n2024\nAdmin For Children‚Äôs Svcs\nAssistant Commissioner For Facilities Development & Const\n264746\n258750\n\n\n2024\nAdmin For Children‚Äôs Svcs\nExecutive Agency Counsel\n264746\n258750\n\n\n2024\nAdmin For Children‚Äôs Svcs\nAdministrative Director Of Social Services\n264835\n258750\n\n\n2024\nAdmin For Children‚Äôs Svcs\nCity Medical Director\n264062\n258750\n\n\n2024\nAdmin For Children‚Äôs Svcs\nCommissioner Of Children‚Äôs Services\n277605\n258750\n\n\n2024\nAdmin For Children‚Äôs Svcs\nStrategic Initiative Specialist\n264746\n258750\n\n\n2024\nAdmin For Children‚Äôs Svcs\nExecutive Agency Counsel\n264835\n258750\n\n\n2024\nAdmin For Children‚Äôs Svcs\nAdministrative Director Of Social Services\n271810\n258750\n\n\n\n\n\nCode\n#calculating amount of agencies that would be affected by the change\nimpacted_agencies &lt;- employees_above_mayor |&gt;  \n  count(agency_name, sort = TRUE) \n#calculating which roles would get impacted by the change\nimpacted_titles &lt;- employees_above_mayor |&gt;  \n  count(title_description, sort = TRUE)  \nkable(slice_head(impacted_agencies, n = 10), caption = \"Top 10 Agencies with Employees Earning More Than the Mayor\")\n\n\n\nTop 10 Agencies with Employees Earning More Than the Mayor\n\n\nagency_name\nn\n\n\n\n\nOffice Of The Comptroller\n65\n\n\nPolice Department\n47\n\n\nOffice Of The Mayor\n44\n\n\nFire Department\n32\n\n\nDept Of Environment Protection\n19\n\n\nAdmin For Children‚Äôs Svcs\n15\n\n\nDept Of Ed Pedagogical\n15\n\n\nOffice Of The Actuary\n15\n\n\nTechnology & Innovation\n15\n\n\nDepartment Of Sanitation\n13\n\n\n\n\n\nCode\nkable(slice_head(impacted_titles, n = 10), caption = \"Top 10 Job Titles with Employees Earning More Than the Mayor\")\n\n\n\nTop 10 Job Titles with Employees Earning More Than the Mayor\n\n\ntitle_description\nn\n\n\n\n\nAdministrative Staff Analyst\n33\n\n\nPresident\n33\n\n\nDirector Of Investments\n27\n\n\nDeputy Commissioner\n25\n\n\nExecutive Director\n18\n\n\nExecutive Agency Counsel\n16\n\n\nComputer Systems Manager\n14\n\n\nFirst Deputy Mayor\n14\n\n\nChief Actuary\n13\n\n\nDeputy Assistant Chief Of Department\n13\n\n\n\n\n\nCode\n#seeing the total amount that would be saved if the policy were to go through\nemployees_above_mayor &lt;- employees_above_mayor |&gt;  \n  mutate(savings = base_salary - base_salary_mayor)  \ntotal_savings &lt;- sum(employees_above_mayor$savings, na.rm = TRUE)\ntotal_people_above_mayor &lt;- nrow(employees_above_mayor)\ncat(\"**Total Savings:**\", total_savings, \"\\n\\n\")\n\n\n**Total Savings:** 8958853 \n\n\nCode\ncat(\"**Total People Above Mayor's Salary:**\", total_people_above_mayor)\n\n\n**Total People Above Mayor's Salary:** 451\n\n\nFor the analysis, we only focused on the base salaries of each role to compare them all to the mayors to see how many people and jobs would be affected by it. We also researched to see the top 10 employees, agencies, and titles affected by the change. The agencies that would be most affected by the policy change would be the Office of the Comptroller, Police Department, Office of the Mayor, and Fire Department and would directly affect over 400 people. According to our calculations, if the policy were to go through the total amount saved throughout all the years documented in the dataset would be $8,958,853, and it would affect 451 jobs.\n\nPolicy 1 Recommendation:\nWe would recommend for CATS to not go through with this policy because although it would significantly reduce payroll costs and prevent excessive overtime spending, it is not worth the risk of employee dissatisfaction which may lead to people quitting their jobs for better paying private sector jobs. Public safety agencies such as the NYPD or Fire Department may need the overtime pay to function effectively so limiting their compensation could lead to staff shortages. Instead of completely capping salaries at mayoral level, there can be a compromise where non-essential workers pay can be capped at the mayoral level while critial roles do not have that cap applied to them."
  },
  {
    "objectID": "mp01.html#policy-2-increasing-staffing-to-reduce-overtime-expenses",
    "href": "mp01.html#policy-2-increasing-staffing-to-reduce-overtime-expenses",
    "title": "New York City Payroll Policy Proposal Analysis",
    "section": "Policy 2: Increasing Staffing to Reduce Overtime Expenses ",
    "text": "Policy 2: Increasing Staffing to Reduce Overtime Expenses \nWe want to find out how many more Full Time Employees (fte in the tables) would be neccesary for overtime expenses to be completely cut to be able to see the scale of the amount of overtime hours worked by employees although it will probably be unlikely that the required amount of new Full Time Employees are fulfilled.\n\n\nCode\n#grouping to find total overtime pay, hours, and average rate of jobs\novertime_analysis &lt;- df |&gt; \n  group_by(agency_name, title_description) |&gt; \n  summarize(\n    total_overtime_hours = sum(ot_hours, na.rm = TRUE),\n    total_overtime_pay = sum(total_ot_paid, na.rm = TRUE),\n    average_hourly_rate = mean(base_salary / 2080, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(\n    required_fte = ceiling(total_overtime_hours / 2080),\n    overtime_cost = total_overtime_hours * average_hourly_rate * 1.5, \n    regular_cost = total_overtime_hours * average_hourly_rate,         \n    potential_savings = overtime_cost - regular_cost\n  )\n#finding the most jobs with total overtime hours and the required amount of new full time employees for the policy to work\novertime_fte_analysis &lt;- df |&gt; \n  group_by(agency_name, title_description) |&gt; \n  summarize(\n    total_overtime_hours = sum(ot_hours, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(\n    required_fte = ceiling(total_overtime_hours / 2080)\n  ) |&gt; \n  arrange(desc(total_overtime_hours))\nkable(head(overtime_fte_analysis, 10), caption = \"Top 10 Job Titles by Overtime FTE Analysis\")\n\n\n\nTop 10 Job Titles by Overtime FTE Analysis\n\n\n\n\n\n\n\n\nagency_name\ntitle_description\ntotal_overtime_hours\nrequired_fte\n\n\n\n\nPolice Department\nPolice Officer\n60270018\n28976\n\n\nFire Department\nFirefighter\n43536213\n20931\n\n\nDepartment Of Correction\nCorrection Officer\n34092745\n16391\n\n\nDepartment Of Sanitation\nSanitation Worker\n23098266\n11105\n\n\nPolice Department\nP.o. Da Det Gr3\n15622342\n7511\n\n\nPolice Department\nSchool Safety Agent\n14982551\n7204\n\n\nNyc Housing Authority\nCaretaker\n9439229\n4539\n\n\nPolice Department\nSergeant-\n8251354\n3967\n\n\nFire Department\nLieutenant\n7607797\n3658\n\n\nPolice Department\nTraffic Enforcement Agent\n6913560\n3324\n\n\n\n\n\nCode\n#calcuating potential savings from each department and how many people would be needed\nagency_savings &lt;- overtime_analysis |&gt; \n  group_by(agency_name) |&gt; \n  summarize(\n    total_potential_savings = sum(potential_savings, na.rm = TRUE),\n    total_required_fte = sum(required_fte, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt; \n  arrange(desc(total_potential_savings))\nkable(head(agency_savings, 10), caption = \"Top 10 Agencies by Potential Savings\")\n\n\n\nTop 10 Agencies by Potential Savings\n\n\n\n\n\n\n\nagency_name\ntotal_potential_savings\ntotal_required_fte\n\n\n\n\nPolice Department\n2589731595\n68333\n\n\nFire Department\n1333482940\n34860\n\n\nDepartment Of Correction\n741593209\n20810\n\n\nDepartment Of Sanitation\n535014906\n15232\n\n\nNyc Housing Authority\n172575977\n12698\n\n\nHra/Dept Of Social Services\n171591017\n6721\n\n\nAdmin For Children‚Äôs Svcs\n148044480\n5113\n\n\nDepartment Of Transportation\n126130646\n6287\n\n\nDept Of Environment Protection\n78524051\n4462\n\n\nDept. Of Homeless Services\n51569931\n2340\n\n\n\n\n\nThe main focus of policy 2 is on staffing and overtime hours, so we analyzed which agencies and roles have the most overtime, unsurprisingly it is the NYPD and Fire Department because their jobs require them to be prepared to work at any moment. Although the potential savings are high, it would be difficult for every missing job to be filled.\nPolicy 2 Recommendation\nWe believe that this policy is not very feasible because of the sheer number new full time employees are needed for certain jobs. Just Police Officers themselves worked over 60,000,000 hours of overtime, and that would require almost 30,000 new full time Police Officers if they wanted to cut overtime expenses totally out from that title. We would recommend limiting the amount of overtime hours an employee can have, with a maximum of 10% of their regular hours. Excess hours will not be paid as overtime but as regular hours. Another suggestion is increasing staffing in smaller agencies and roles first and continually monitor it to see how much payroll is saved and scale it if it is successful."
  },
  {
    "objectID": "mp01.html#policy-3-adjusting-pay-based-on-geographic-location",
    "href": "mp01.html#policy-3-adjusting-pay-based-on-geographic-location",
    "title": "New York City Payroll Policy Proposal Analysis",
    "section": "Policy 3: Adjusting Pay Based on Geographic Location ",
    "text": "Policy 3: Adjusting Pay Based on Geographic Location \nTo analyze our suggestion to CATS, we looked at only 4 boroughs which were Manhattan, Brooklyn, Queens, and Bronx because the dataset did not have Staten Island in it. Through our analysis we are comparing salaries across boroughs and estimating savings by reducing salaries in lower-cost areas.\n\n\nCode\n#consolidating data to only the 4 boroughs\nnyc_boroughs &lt;- c(\"Manhattan\", \"Brooklyn\", \"Queens\", \"Bronx\")\nnyc_data &lt;- df |&gt; \n  filter(work_location_borough %in% nyc_boroughs)\n#finding the average salary per borough\nborough_salary_nyc &lt;- nyc_data |&gt; \n  group_by(work_location_borough) |&gt; \n  summarize(avg_base_salary = mean(base_salary, na.rm = TRUE), .groups = 'drop')\nkable(borough_salary_nyc, caption = \"Average Base Salary for NYC Boroughs\")\n\n\n\nAverage Base Salary for NYC Boroughs\n\n\nwork_location_borough\navg_base_salary\n\n\n\n\nBronx\n51598.13\n\n\nBrooklyn\n55627.04\n\n\nManhattan\n40990.79\n\n\nQueens\n54643.50\n\n\n\n\n\nCode\n#finding lowest cost borough\nlowest_cost_borough &lt;- borough_salary_nyc |&gt; \n  filter(avg_base_salary == min(avg_base_salary)) |&gt; \n  pull(work_location_borough)\nprint(paste(\"Lowest-Cost Borough:\", lowest_cost_borough))\n\n\n[1] \"Lowest-Cost Borough: Manhattan\"\n\n\nCode\n#adjusteding salaries by lowering it by 10% if it was not in the lowest cost borough\nadjusted_salaries &lt;- nyc_data |&gt; \n  left_join(borough_salary_nyc, by = \"work_location_borough\") |&gt; \n  mutate(\n    adjusted_salary = ifelse(\n      work_location_borough != lowest_cost_borough,\n      base_salary * 0.9,  \n      base_salary\n    ),\n#calculating salary reductions\n    salary_reduction = pmax(0, base_salary - adjusted_salary)\n  )\n#calculating total savings from the reductions\ntotal_savings &lt;- sum(adjusted_salaries$salary_reduction, na.rm = TRUE)\npaste(\"Total Potential Savings by Adjusting Salaries:\", dollar(total_savings))\n\n\n[1] \"Total Potential Savings by Adjusting Salaries: $7,793,789,406\"\n\n\nCode\nsavings_by_borough &lt;- adjusted_salaries |&gt; \n  group_by(work_location_borough) |&gt; \n  summarize(total_savings = sum(salary_reduction, na.rm = TRUE), .groups = 'drop') |&gt; \n  arrange(desc(total_savings))\nkable(savings_by_borough, caption = \"Potential Savings by Borough\")\n\n\n\nPotential Savings by Borough\n\n\nwork_location_borough\ntotal_savings\n\n\n\n\nQueens\n3398011415\n\n\nBrooklyn\n2916892892\n\n\nBronx\n1478885099\n\n\nManhattan\n0\n\n\n\n\n\nPolicy 3 Recommendation\nAs we can see from the analysis, since Manhattan is the lowest cost borough by a massive amount so they do not get a reduction in salary while the other 3 boroughs get a reduction. We decided that the reduction would be 10% of their base salaries and it would be almost $8,000,000 in potential savings if the policy were to go through. This change would be beneficial for CATS as they are looking to cut payroll costs."
  },
  {
    "objectID": "mp01.html#conclusion",
    "href": "mp01.html#conclusion",
    "title": "New York City Payroll Policy Proposal Analysis",
    "section": " Conclusion ",
    "text": "Conclusion \nOverall based on our analysis of the payroll data, New York City‚Äôs payroll policies need some sort of reform to cut costs but also needs to be balanced to keep employee retention high. Capping salaries at the mayoral level may have the potential of losing highly skilled employees in their respective fields. Increasing staff is difficult to do when overtime plays a big role in some of these jobs and it is not possible to fill in all the overtime hours with new full time employees. Adjusting pay based on the borough allows for fair compensation aligning with different costs of living. To cut down on payroll spending and optimize the taxpayer‚Äôs money we recommend a hybrid combination of the recommendations to maintain financial sustanability in New York city."
  }
]